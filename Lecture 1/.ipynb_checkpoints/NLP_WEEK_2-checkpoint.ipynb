{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2c4724-7998-4103-a66c-bc520be99446",
   "metadata": {},
   "source": [
    "$\\textbf{Why study Natural Language Processing and Computational Linguistics?}$\n",
    "\n",
    "- Text everywhere!\n",
    "- Profit! (Customer segmentation and profiling)\n",
    "- Qualitattive research\n",
    "- Style analysis and forensics\n",
    "\n",
    "$\\textbf{What's the difference between NLP and CL?}$\n",
    "\n",
    "- NLP: Statistics $+$ Computers to process languages (TF-IDF, Word frequencies, stopwords removal)\n",
    "- CL: Statistics $+$ Computers to perform linguistic tasks (identifying parts-of-speech, tagging of grammars and stopwords)\n",
    "- Text Analytics: NLP + CL.\n",
    "\n",
    "$\\textbf{Abused Terms in NLP:}$\n",
    "\n",
    "- Machine Learning: teaching machines to find, and learn from, patterns.\n",
    "- Information Retrieval: Querying of text information (think SQL).\n",
    "- B.I.: Generating insights from data (think descriptive analytics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67feaf38-1c10-4659-a1b1-fc5adc4b2452",
   "metadata": {},
   "source": [
    "$\\textbf{Where my data at?}$\n",
    "\n",
    "- Look for a corpus\n",
    "- Corpus: A collection of large and structured set of texts.\n",
    "- American National Corpus: https://anc.org\n",
    "- British National Corpus: http://www.natcorp.ox.ac.uk\n",
    "- Corpuses (not to be confused with corpses): https://en.wikipedia.org/wiki/List_of_text_corpora\n",
    "- The iconic Brown Corpus\n",
    "\n",
    "$\\textbf{Note:}$\n",
    "\n",
    "- No two corpuses are the same.\n",
    "- Differs in POS Tagging and NER Tagging.\n",
    "- Some corpora are built for clustering and classification and not on POS and NER.\n",
    "- What's clustering?\n",
    "- What's classification?\n",
    "\n",
    "$\\textbf{More on data:}$\n",
    "\n",
    "- Scrape the web!\n",
    "- Beautiful Soup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "- urllib: https://docs.python.org/2/library/urllib.html\n",
    "- scrapy: https://scrapy.org\n",
    "- selenium: https://scrapy.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebcce5-3c26-4fcd-a11e-14d8c094f3ad",
   "metadata": {},
   "source": [
    "$\\textbf{Garbage In - Garbage Out}$\n",
    "\n",
    "- Understand your data.\n",
    "- Proper preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b1662-1159-4b5e-9937-4a33116fcfc4",
   "metadata": {},
   "source": [
    "$\\textbf{spaCY}$\n",
    "\n",
    "- An industrial grade NLP.\n",
    "- Not for academic research: One algorithm for POS and for NER (per language).\n",
    "- Not bloated with unecessary features.\n",
    "\n",
    "$What do you mean by Not for academic research?$\n",
    "\n",
    "- A large number of open source packages in NLP are maintained by reseachers in academia, while they do worlk (NLTK for example), these packags do not provide implementations to productionaize NLP tasks (not scalable).\n",
    "\n",
    "$\\textbf{Install spaCY}$\n",
    "\n",
    "- pip install -U spacy\n",
    "\n",
    "$\\textbf{Installing Language Models in spaCY}$\n",
    "\n",
    "- A language model: statistical models that allows to perform NLP tasks on languages.\n",
    "\n",
    "- Different language models = different NLP tasks  = different models\n",
    "\n",
    "- Different models for same language, (what's the general difference?)\n",
    "\n",
    "- in the comman line: spacy download en (English model,de for German, es for Spanish, fr for French, xx for multi language model)\n",
    "\n",
    "- To load the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aebc2c-f9c7-41fb-a726-8a0c787ed299",
   "metadata": {},
   "source": [
    "$\\textbf{Basic Preprocessing with Language Models}$\n",
    "\n",
    "$\\textbf{1. Tokenizing Texts}$\n",
    "\n",
    "- The task of spiltting a text into segments called tokens.\n",
    "- Tokens can be words, punctuations, numbers, and other special characters.\n",
    "\n",
    "$\\textbf{Example}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c80712-f954-4076-b464-762219e405b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jump over the lazy dog.\"\n",
    "\n",
    "sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762215d-11e4-4f01-892c-b35c0f21d3a7",
   "metadata": {},
   "source": [
    "$\\textbf{2. Parts of Speech Taggig}$\n",
    "\n",
    "- The nature of a word if its a conjuction, pronouns, verb, adverb, adjective, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465668a2-073b-4f1a-94b4-eb0c57abc45a",
   "metadata": {},
   "source": [
    "$\\textbf{3. Dependency Parsing}$\n",
    "\n",
    "- Analyzes stings as symbols, and the relationship of these symbols towards each other.\n",
    "\n",
    "$\\textbf{Example}$ \n",
    "The Dog chased the brown cat\n",
    "\n",
    "The dog (noun and subject of the sentence)\n",
    "chased (linking verb)\n",
    "the brown cat (noun and object of the sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8533d-a0fa-4ba7-8ceb-d852b3b3f591",
   "metadata": {},
   "source": [
    "$\\textbf{4. Named Entity Recognition}$\n",
    "\n",
    "- Recognizing names of people, country, product, or organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31ea00-d734-44f1-b8bc-527ae1dcfaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
